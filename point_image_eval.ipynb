{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "/home/sina/env_prediction_project/trajectory_detection/video_samples/location_5_pose_4.jpg does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     52\u001b[39m H, _ = cv2.findHomography(image_points, real_world_points)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Run YOLO on the frame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Extract detections\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/yolotracker/lib/python3.13/site-packages/ultralytics/engine/model.py:182\u001b[39m, in \u001b[36mModel.__call__\u001b[39m\u001b[34m(self, source, stream, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    154\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    155\u001b[39m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image.Image, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np.ndarray, torch.Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    156\u001b[39m     stream: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    157\u001b[39m     **kwargs: Any,\n\u001b[32m    158\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m    159\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[33;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[32m    161\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    180\u001b[39m \u001b[33;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/yolotracker/lib/python3.13/site-packages/ultralytics/engine/model.py:550\u001b[39m, in \u001b[36mModel.predict\u001b[39m\u001b[34m(self, source, stream, predictor, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.predictor, \u001b[33m\"\u001b[39m\u001b[33mset_prompts\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[32m    549\u001b[39m     \u001b[38;5;28mself\u001b[39m.predictor.set_prompts(prompts)\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.predictor.predict_cli(source=source) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/yolotracker/lib/python3.13/site-packages/ultralytics/engine/predictor.py:214\u001b[39m, in \u001b[36mBasePredictor.__call__\u001b[39m\u001b[34m(self, source, model, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream_inference(source, model, *args, **kwargs)\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/yolotracker/lib/python3.13/site-packages/torch/utils/_contextlib.py:36\u001b[39m, in \u001b[36m_wrap_generator.<locals>.generator_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m         response = \u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     39\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     40\u001b[39m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/yolotracker/lib/python3.13/site-packages/ultralytics/engine/predictor.py:295\u001b[39m, in \u001b[36mBasePredictor.stream_inference\u001b[39m\u001b[34m(self, source, model, *args, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m.setup_model(model)\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:  \u001b[38;5;66;03m# for thread-safe inference\u001b[39;00m\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# Setup source every time predict is called\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msetup_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m     \u001b[38;5;66;03m# Check if save_dir/ label file exists\u001b[39;00m\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_txt:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/yolotracker/lib/python3.13/site-packages/ultralytics/engine/predictor.py:255\u001b[39m, in \u001b[36mBasePredictor.setup_source\u001b[39m\u001b[34m(self, source)\u001b[39m\n\u001b[32m    245\u001b[39m \u001b[38;5;28mself\u001b[39m.imgsz = check_imgsz(\u001b[38;5;28mself\u001b[39m.args.imgsz, stride=\u001b[38;5;28mself\u001b[39m.model.stride, min_dim=\u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# check image size\u001b[39;00m\n\u001b[32m    246\u001b[39m \u001b[38;5;28mself\u001b[39m.transforms = (\n\u001b[32m    247\u001b[39m     \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m    248\u001b[39m         \u001b[38;5;28mself\u001b[39m.model.model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    253\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    254\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m \u001b[38;5;28mself\u001b[39m.dataset = \u001b[43mload_inference_source\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28mself\u001b[39m.source_type = \u001b[38;5;28mself\u001b[39m.dataset.source_type\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    263\u001b[39m     \u001b[38;5;28mself\u001b[39m.source_type.stream\n\u001b[32m    264\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.source_type.screenshot\n\u001b[32m    265\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset) > \u001b[32m1000\u001b[39m  \u001b[38;5;66;03m# many images\u001b[39;00m\n\u001b[32m    266\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33mvideo_flag\u001b[39m\u001b[33m\"\u001b[39m, [\u001b[38;5;28;01mFalse\u001b[39;00m]))\n\u001b[32m    267\u001b[39m ):  \u001b[38;5;66;03m# videos\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/yolotracker/lib/python3.13/site-packages/ultralytics/data/build.py:253\u001b[39m, in \u001b[36mload_inference_source\u001b[39m\u001b[34m(source, batch, vid_stride, buffer)\u001b[39m\n\u001b[32m    251\u001b[39m     dataset = LoadPilAndNumpy(source)\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     dataset = \u001b[43mLoadImagesAndVideos\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[38;5;66;03m# Attach source types to the dataset\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[38;5;28msetattr\u001b[39m(dataset, \u001b[33m\"\u001b[39m\u001b[33msource_type\u001b[39m\u001b[33m\"\u001b[39m, source_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/yolotracker/lib/python3.13/site-packages/ultralytics/data/loaders.py:342\u001b[39m, in \u001b[36mLoadImagesAndVideos.__init__\u001b[39m\u001b[34m(self, path, batch, vid_stride)\u001b[39m\n\u001b[32m    340\u001b[39m         files.append(\u001b[38;5;28mstr\u001b[39m((parent / p).absolute()))  \u001b[38;5;66;03m# files (relative to *.txt file parent)\u001b[39;00m\n\u001b[32m    341\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not exist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# Define files as images or videos\u001b[39;00m\n\u001b[32m    345\u001b[39m images, videos = [], []\n",
      "\u001b[31mFileNotFoundError\u001b[39m: /home/sina/env_prediction_project/trajectory_detection/video_samples/location_5_pose_4.jpg does not exist"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# Load YOLOv8 pose model\n",
    "model = YOLO(\"yolov8n-pose.pt\")\n",
    "\n",
    "# Initialize variables\n",
    "frame_count = 0 # Timestep counter\n",
    "waypoints = [] # Store waypoints\n",
    "ped_id = 1.0 # Person ID\n",
    "\n",
    "file_name = 'location_5_pose_4'\n",
    "video_path = f\"/home/sina/env_prediction_project/trajectory_detection/video_samples/{file_name}.jpg\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Make directory to save waypoints\n",
    "output_dir = f\"./image_eval\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Desired framerate\n",
    "desired_fps = 25\n",
    "frame_delay = int(1000 / desired_fps)\n",
    "\n",
    "### Homography: define image & real-world points\n",
    "# ## In Lab - Door corner\n",
    "# image_points = np.array([\n",
    "#     [319, 58], [547, 132], [382, 313], [127, 209]\n",
    "# ], dtype=np.float32)\n",
    "# real_world_points = np.array([\n",
    "#     [72, 84], [192, 84], [192, -36], [72, -36]\n",
    "# ], dtype=np.float32)\n",
    "\n",
    "## In Lab - Mata's Desk\n",
    "image_points = np.array([\n",
    "    [547, 132], [1135, 231], [1066, 590], [432, 512]\n",
    "], dtype=np.float32)\n",
    "real_world_points = np.array([\n",
    "    [253, 151], [13, 91], [13, 271], [193, 331]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# # ## Big Aisle - Left side of orange cone\n",
    "# image_points = np.array([\n",
    "#     [224, 184], [504, 164], [544, 506], [154, 539]\n",
    "# ], dtype=np.float32)\n",
    "# real_world_points = np.array([\n",
    "#     [0, 180], [120, 180], [120, 0], [0, 0]\n",
    "# ], dtype=np.float32)\n",
    "\n",
    "H, _ = cv2.findHomography(image_points, real_world_points)\n",
    "\n",
    "\n",
    "# Run YOLO on the frame\n",
    "results = model(video_path)\n",
    "\n",
    "# Extract detections\n",
    "for result in results:\n",
    "    keypoints = result.keypoints\n",
    "    boxes = result.boxes\n",
    "\n",
    "    if keypoints.has_visible:\n",
    "        for box_conf, kps in zip(boxes.conf.cpu().numpy(), keypoints.data.cpu().numpy()):\n",
    "            if box_conf < 0.1:\n",
    "                continue\n",
    "            # for kp in kps:\n",
    "            # kp shape: (17, 3) => (x, y, confidence)\n",
    "                # kp = kp.cpu().numpy()\n",
    "            keypoint_confidences = kps[:, 2]\n",
    "            avg_conf = np.mean(keypoint_confidences)\n",
    "            # if avg_conf > 0.48:\n",
    "            left_ankle = kps[15]  # x, y, conf\n",
    "            right_ankle = kps[16]\n",
    "\n",
    "            if left_ankle[2] > 0.10 and right_ankle[2] > 0.10:\n",
    "                cx = (left_ankle[0] + right_ankle[0]) / 2\n",
    "                cy = (left_ankle[1] + right_ankle[1]) / 2\n",
    "\n",
    "                # Apply homography\n",
    "                # X, Y =  np.array([cx, cy], dtype=np.float32)\n",
    "                input_point = np.array([[cx, cy]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "                transformed_point = cv2.perspectiveTransform(input_point, H)\n",
    "                X, Y = transformed_point[0][0]\n",
    "\n",
    "                waypoints.append((frame_count, X, Y))\n",
    "                    \n",
    "            else:\n",
    "                waypoints.append((frame_count, None, None))\n",
    "    else:\n",
    "        waypoints.append((frame_count, None, None))\n",
    "\n",
    "\n",
    "# Save full-resolution waypoints\n",
    "with open(os.path.join(output_dir, f\"points_loc.txt\"), \"a\") as f:\n",
    "    # f.truncate(0)\n",
    "    for point in waypoints:\n",
    "        f.write(f\"{point[0]}\\t{ped_id}\\t{point[1]}\\t{point[2]}\\n\")\n",
    "\n",
    "print(\"Waypoints saved to\", os.path.join(output_dir, \"loc1_pose_waypoints.txt\"))\n",
    "\n",
    "# # Sampling\n",
    "# freq = 2.5  # 1 Hz\n",
    "# sampling_interval = int(desired_fps / freq)\n",
    "# sampled_waypoints = []\n",
    "\n",
    "# for i in range(0, len(waypoints), sampling_interval):\n",
    "#     group = waypoints[i:i + sampling_interval]\n",
    "#     valid_points = [(X, Y) for _, X, Y in group if X is not None and Y is not None]\n",
    "\n",
    "#     if valid_points:\n",
    "#         avg_X = sum(p[0] for p in valid_points) / len(valid_points)\n",
    "#         avg_Y = sum(p[1] for p in valid_points) / len(valid_points)\n",
    "#         sampled_waypoints.append((group[0][0], avg_X, avg_Y))\n",
    "\n",
    "# # Save sampled waypoints\n",
    "# with open(os.path.join(output_dir, \"pose_waypoints_sampled.txt\"), \"w\") as f:\n",
    "#     f.truncate(0)\n",
    "#     for point in sampled_waypoints:\n",
    "#         f.write(f\"{point[0]}\\t{ped_id}\\t{point[1]:.2f}\\t{point[2]:.2f}\\n\")\n",
    "\n",
    "# print(\"Sampled waypoints saved to\", os.path.join(output_dir, \"pose_waypoints_sampled.txt\"))\n",
    "\n",
    "# # Smoothing\n",
    "# def moving_average(data, window_size=5):\n",
    "#     smoothed = []\n",
    "#     for i in range(len(data)):\n",
    "#         window = data[max(0, i - window_size + 1):i + 1]\n",
    "#         avg_x = sum(p[1] for p in window) / len(window)\n",
    "#         avg_y = sum(p[2] for p in window) / len(window)\n",
    "#         smoothed.append((data[i][0], avg_x, avg_y))\n",
    "#     return smoothed\n",
    "\n",
    "# smoothed_waypoints = moving_average(sampled_waypoints)\n",
    "\n",
    "# # Save smoothed waypoints\n",
    "# with open(os.path.join(output_dir, \"pose_waypoints_smoothed.txt\"), \"w\") as f:\n",
    "#     for point in smoothed_waypoints:\n",
    "#         f.write(f\"{point[0]}\\t{ped_id}\\t{point[1]:.2f}\\t{point[2]:.2f}\\n\")\n",
    "\n",
    "# print(\"Smoothed waypoints saved to\", os.path.join(output_dir, \"pose_waypoints_smoothed.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Distance in loc 1: 8.53781259894471\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# Define the reference point\n",
    "reference_point = np.array([193, 271])\n",
    "\n",
    "# Initialize a list to store distances\n",
    "distances = []\n",
    "\n",
    "# Read the file and calculate distances\n",
    "file_path = \"/home/sina/env_prediction_project/trajectory_detection/image_eval/points_loc1.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        columns = line.strip().split(\"\\t\")\n",
    "        try:\n",
    "            x, y = float(columns[-2]), float(columns[-1])\n",
    "            point = np.array([x, y])\n",
    "            distance = np.linalg.norm(point - reference_point)\n",
    "            distances.append(distance)\n",
    "        except ValueError:\n",
    "            # Skip lines with invalid data\n",
    "            print(\"Invalid data:\", line)\n",
    "            continue\n",
    "\n",
    "# Calculate the average distance\n",
    "average_distance = np.mean(distances)\n",
    "print(\"Average Distance in loc 1:\", average_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Distance in loc 2: 9.259232830503045\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# Define the reference point\n",
    "reference_point = np.array([193, 151])\n",
    "\n",
    "# Initialize a list to store distances\n",
    "distances = []\n",
    "\n",
    "# Read the file and calculate distances\n",
    "file_path = \"/home/sina/env_prediction_project/trajectory_detection/image_eval/points_loc2.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        columns = line.strip().split(\"\\t\")\n",
    "        try:\n",
    "            x, y = float(columns[-2]), float(columns[-1])\n",
    "            point = np.array([x, y])\n",
    "            distance = np.linalg.norm(point - reference_point)\n",
    "            distances.append(distance)\n",
    "        except ValueError:\n",
    "            # Skip lines with invalid data\n",
    "            print(\"Invalid data:\", line)\n",
    "            continue\n",
    "\n",
    "# Calculate the average distance\n",
    "average_distance = np.mean(distances)\n",
    "print(\"Average Distance in loc 2:\", average_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Distance in loc 3: 10.01450752051745\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# Define the reference point\n",
    "reference_point = np.array([133, 331])\n",
    "\n",
    "# Initialize a list to store distances\n",
    "distances = []\n",
    "\n",
    "# Read the file and calculate distances\n",
    "file_path = \"/home/sina/env_prediction_project/trajectory_detection/image_eval/points_loc3.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        columns = line.strip().split(\"\\t\")\n",
    "        try:\n",
    "            x, y = float(columns[-2]), float(columns[-1])\n",
    "            point = np.array([x, y])\n",
    "            distance = np.linalg.norm(point - reference_point)\n",
    "            distances.append(distance)\n",
    "        except ValueError:\n",
    "            # Skip lines with invalid data\n",
    "            print(\"Invalid data:\", line)\n",
    "            continue\n",
    "\n",
    "# Calculate the average distance\n",
    "average_distance = np.mean(distances)\n",
    "print(\"Average Distance in loc 3:\", average_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Distance in loc 4: 13.482207319515249\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# Define the reference point\n",
    "reference_point = np.array([73, 151])\n",
    "\n",
    "# Initialize a list to store distances\n",
    "distances = []\n",
    "\n",
    "# Read the file and calculate distances\n",
    "file_path = \"/home/sina/env_prediction_project/trajectory_detection/image_eval/points_loc4.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        columns = line.strip().split(\"\\t\")\n",
    "        try:\n",
    "            x, y = float(columns[-2]), float(columns[-1])\n",
    "            point = np.array([x, y])\n",
    "            distance = np.linalg.norm(point - reference_point)\n",
    "            distances.append(distance)\n",
    "        except ValueError:\n",
    "            # Skip lines with invalid data\n",
    "            print(\"Invalid data:\", line)\n",
    "            continue\n",
    "\n",
    "# Calculate the average distance\n",
    "average_distance = np.mean(distances)\n",
    "print(\"Average Distance in loc 4:\", average_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Distance in loc 5: 13.210248892037049\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# Define the reference point\n",
    "reference_point = np.array([373, 271])\n",
    "\n",
    "# Initialize a list to store distances\n",
    "distances = []\n",
    "\n",
    "# Read the file and calculate distances\n",
    "file_path = \"/home/sina/env_prediction_project/trajectory_detection/image_eval/points_loc5.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        columns = line.strip().split(\"\\t\")\n",
    "        try:\n",
    "            x, y = float(columns[-2]), float(columns[-1])\n",
    "            point = np.array([x, y])\n",
    "            distance = np.linalg.norm(point - reference_point)\n",
    "            distances.append(distance)\n",
    "        except ValueError:\n",
    "            # Skip lines with invalid data\n",
    "            print(\"Invalid data:\", line)\n",
    "            continue\n",
    "\n",
    "# Calculate the average distance\n",
    "average_distance = np.mean(distances)\n",
    "print(\"Average Distance in loc 5:\", average_distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolotracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
